{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "b3OxrTARWR0p",
        "outputId": "9cad0f87-26ee-4734-fed0-1c74843f742b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9b3d232c18a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/timmmaster'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../input/timmmaster')\n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preliminaries\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visuals and CV2\n",
        "import cv2\n",
        "\n",
        "# albumentations for augs\n",
        "import albumentations\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "#torch\n",
        "import torch\n",
        "import timm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import cudf\n",
        "import cuml\n",
        "import cupy\n",
        "from cuml.feature_extraction.text import TfidfVectorizer\n",
        "from cuml import PCA\n",
        "from cuml.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "id": "h53H_vnFbTBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configuration class\n",
        "\n",
        "class CFG:\n",
        "    loss_module='ArcFace'\n",
        "    TRAIN_DIR='../train.csv'\n",
        "    TEST_DIR='../test.csv'\n",
        "    seed = 123 \n",
        "    img_size = 512\n",
        "    classes = 11014\n",
        "    fc_dim = 512\n",
        "    epochs = 25\n",
        "    batch_size = 12\n",
        "    num_workers = 3\n",
        "    model_name = 'tf_efficientnet_b3'\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model_path_arcface='../input/pretrained-b3/Train_F1_score_0.9061769859813084valid_f1_score0.4245035046728972_Epoch_0_lr_start_2.23e-05_lr_max_0.00016_softmax_512x512_tf_efficientnet_b0.pt'\n",
        "    model_path_softmax = '../input/label-classfier-model/2022-04-15_softmax_512x512_tf_efficientnet_b4.pt'\n",
        "    # # check true when we want to train the model\n",
        "    isTraining=False"
      ],
      "metadata": {
        "id": "qRA1axYJbXBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "tR2cMqtVbmti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset():\n",
        "\n",
        "    # if not in testing phase read train dataset else test dataset\n",
        "    df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
        "    # we have information that label_group is same for similar kind of product\n",
        "    # let's use this to get F1 score for our final model\n",
        "    tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
        "    df['matches'] = df['label_group'].map(tmp)\n",
        "    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
        "    # get cuda frame for faster GPU computation\n",
        "    df_cu = cudf.DataFrame(df)\n",
        "    \n",
        "        \n",
        "    return df, df_cu"
      ],
      "metadata": {
        "id": "po4mZ928bZjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset"
      ],
      "metadata": {
        "id": "akN8DQBrbiKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShopeeQueryDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, imagePath, transform=None):\n",
        "        self.imagePath = imagePath\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imagePath)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        " \n",
        "        row = self.imagePath[idx]\n",
        "        # read image convert to RGB and apply augmentation\n",
        "        image = cv2.imread(row)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        # apply transformation\n",
        "        if self.transform:\n",
        "            aug = self.transform(image=image)\n",
        "            image = aug['image']\n",
        "        \n",
        "        return image, torch.tensor(1).long()"
      ],
      "metadata": {
        "id": "Bzr6Y3ddbbr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_transforms():\n",
        "\n",
        "    return albumentations.Compose(\n",
        "        [\n",
        "            albumentations.Resize(CFG.img_size,CFG.img_size,always_apply=True),\n",
        "            albumentations.Normalize(),\n",
        "        ToTensorV2(p=1.0)\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "S4aJxR6QbkYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "s1q3E1a_bs5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 : Product Classfier Softmax Loss"
      ],
      "metadata": {
        "id": "33H0k7BfbxPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShopeeLabelGroupClassfier(nn.Module):\n",
        "    \n",
        "    def __init__(self,\n",
        "                     model_name='tf_efficientnet_b0',\n",
        "                     loss_fn='softmax',\n",
        "                     classes = CFG.classes,\n",
        "                     fc_dim = CFG.fc_dim,\n",
        "                     pretrained=False,\n",
        "                     use_fc=True,\n",
        "                     isTraining=False\n",
        "                ):\n",
        "        \n",
        "        \n",
        "        super(ShopeeLabelGroupClassfier,self).__init__()\n",
        "        \n",
        "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
        "        in_features = self.backbone.classifier.in_features\n",
        "        self.backbone.classifier = nn.Identity()\n",
        "        self.backbone.global_pool = nn.Identity()\n",
        "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.use_fc = use_fc\n",
        "        self.loss_fn =loss_fn\n",
        "        self.isTraining = isTraining\n",
        "        \n",
        "        if self.use_fc:\n",
        "            self.dropout = nn.Dropout(0.2)\n",
        "            self.fc = nn.Linear(in_features,fc_dim )\n",
        "            self.bn = nn.BatchNorm1d(fc_dim)\n",
        "            in_features = fc_dim\n",
        "        self.loss_fn = loss_fn\n",
        "        \n",
        "        if self.loss_fn=='softmax':\n",
        "            self.final = nn.Linear(in_features, CFG.classes)\n",
        "    \n",
        "    def forward(self, image, label):\n",
        "        features = self.get_features(image)\n",
        "        if self.loss_fn=='softmax' and CFG.isTraining:\n",
        "            logits = self.final(features)\n",
        "            return logits\n",
        "        else:\n",
        "            return features\n",
        "    \n",
        "    def get_features(self,inp):\n",
        "        batch_dim = inp.shape[0]\n",
        "        inp = self.backbone(inp)\n",
        "        inp = self.pooling(inp).view(batch_dim, -1)\n",
        "        if self.use_fc and self.isTraining:\n",
        "            inp = self.dropout(inp)\n",
        "            inp = self.fc(inp)\n",
        "            inp = self.bn(inp)\n",
        "        return inp"
      ],
      "metadata": {
        "id": "xB_fFh14brVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: Product Classfier ArcFace Loss"
      ],
      "metadata": {
        "id": "JzwLUG8Db5kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ArcFaceModule(nn.Module):\n",
        "    def __init__(self, in_features, out_features, scale, margin, easy_margin=False, ls_eps=0.0 ):\n",
        "        super(ArcFaceModule, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.scale = scale\n",
        "        self.margin = margin\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        self.easy_margin=easy_margin\n",
        "        self.ls_eps=ls_eps\n",
        "        self.cos_m = math.cos(margin)\n",
        "        self.sin_m = math.sin(margin)\n",
        "        self.th = math.cos(math.pi - margin)\n",
        "        self.mm = math.sin(math.pi - margin) * margin\n",
        "        \n",
        "        \n",
        "        \n",
        "    \n",
        "    def forward(self, input, label):\n",
        "        \n",
        "        # cosine = X.W = ||X|| .||W|| . cos(theta) \n",
        "        # if X and W are normalize then dot product X, W = will be cos theta\n",
        "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
        "        # phi = cos(theta + margin) = cos theta . cos(margin) -  sine theta .  sin(margin)\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = torch.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "            \n",
        "        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n",
        "        # one hot encoded\n",
        "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
        "        #  output = label == True ? phi : cosine  \n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        # scale the output\n",
        "        output *= self.scale\n",
        "        # return cross entropy loss on scalled output\n",
        "        return output, nn.CrossEntropyLoss()(output,label)"
      ],
      "metadata": {
        "id": "YA6qIfUab6cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShopeeEncoderBackBone(nn.Module):\n",
        "    \n",
        "    def __init__(self,\n",
        "                     model_name='tf_efficientnet_b3',\n",
        "                     loss_fn='ArcFace',\n",
        "                     classes = CFG.classes,\n",
        "                     fc_dim = CFG.fc_dim,\n",
        "                     pretrained=False,\n",
        "                     use_fc=True,\n",
        "                     isTraining=False\n",
        "                ):\n",
        "        \n",
        "        \n",
        "        super(ShopeeEncoderBackBone,self).__init__()\n",
        "        \n",
        "        # create bottlenack backbone network from pretrained model \n",
        "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
        "        in_features = self.backbone.classifier.in_features\n",
        "        self.backbone.classifier = nn.Identity()\n",
        "        self.backbone.global_pool = nn.Identity()\n",
        "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.use_fc = use_fc\n",
        "        self.loss_fn =loss_fn\n",
        "        self.isTraining =isTraining\n",
        "        \n",
        "        # build top fc layers (Embedding that we are looking at testing time to represent the entire image)\n",
        "        # this will work as regularizer\n",
        "        if self.use_fc:\n",
        "            self.dropout = nn.Dropout(0.2)\n",
        "            self.fc = nn.Linear(in_features,fc_dim )\n",
        "            self.bn = nn.BatchNorm1d(fc_dim)\n",
        "            self.init_params()\n",
        "            in_features = fc_dim\n",
        "        self.loss_fn = loss_fn\n",
        "        if self.loss_fn=='softmax':\n",
        "            self.final = nn.Linear(in_features, CFG.classes)\n",
        "        elif self.loss_fn =='ArcFace':\n",
        "            self.final = ArcFaceModule( in_features,\n",
        "                                        CFG.classes,\n",
        "                                        scale = 30,\n",
        "                                        margin = 0.5,\n",
        "                                        easy_margin = False,\n",
        "                                        ls_eps = 0.0)\n",
        "            \n",
        "    def forward(self, image, label):\n",
        "        features = self.get_features(image)\n",
        "        if self.isTraining:\n",
        "            logits = self.final(features, label)\n",
        "            return logits\n",
        "        else:\n",
        "            return features\n",
        "    \n",
        "    def init_params(self):\n",
        "        nn.init.xavier_normal_(self.fc.weight)\n",
        "        nn.init.constant_(self.fc.bias,0)\n",
        "        nn.init.constant_(self.bn.weight, 1)\n",
        "        nn.init.constant_(self.bn.bias, 0)\n",
        "        \n",
        "        \n",
        "    def get_features(self,inp):\n",
        "        batch_dim = inp.shape[0]\n",
        "        inp = self.backbone(inp)\n",
        "        inp = self.pooling(inp).view(batch_dim, -1)\n",
        "        if self.use_fc and self.isTraining:\n",
        "            inp = self.dropout(inp)\n",
        "            inp = self.fc(inp)\n",
        "            inp = self.bn(inp)\n",
        "            \n",
        "        return inp"
      ],
      "metadata": {
        "id": "gOunacyNcBmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "\n",
        "def getPretrainedModel(loss_module='ArcFace', model_path=CFG.model_path_arcface, device=CFG.device) :\n",
        "    \n",
        "    if loss_module== 'ArcFace':\n",
        "        # load arcface loss classfier\n",
        "        model = ShopeeEncoderBackBone()\n",
        "        model.load_state_dict(torch.load(CFG.model_path_arcface, map_location=CFG.device))\n",
        "        model = model.to(CFG.device)\n",
        "        return model\n",
        "    else:\n",
        "        #load softmax classfier\n",
        "        model = ShopeeLabelGroupClassfier()\n",
        "        model.load_state_dict(torch.load(CFG.model_path_softmax, map_location=CFG.device))\n",
        "        model = model.to(CFG.device)\n",
        "        return model"
      ],
      "metadata": {
        "id": "yr3sgfIScEty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Embeddings"
      ],
      "metadata": {
        "id": "_yZXFF6TcHQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images_path(df, root_dir):\n",
        "    imagepaths = [ root_dir + \"/\"+image for image in df['image'].tolist()]\n",
        "    return imagepaths"
      ],
      "metadata": {
        "id": "XkeebWZ1cKgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getEmbeddings(queryImagesPath, model, transform=None):\n",
        "    # create dataset from image paths\n",
        "    query_dataset = ShopeeQueryDataset(queryImagesPath,  transform = transform)\n",
        "    \n",
        "    # create dataloader\n",
        "    query_dataloader = torch.utils.data.DataLoader(\n",
        "                                                query_dataset,\n",
        "        batch_size=16\n",
        "    )\n",
        "    \n",
        "    \n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "         \n",
        "        for idx, datax  in tqdm(enumerate(query_dataloader)):\n",
        "            image, label = datax\n",
        "            image = image.to(CFG.device)\n",
        "            label = label.to(CFG.device)\n",
        "            # forward pass to get features\n",
        "            features = model(image, label)\n",
        "            image_embeddings = features.detach().cpu().numpy()\n",
        "            embeddings.append(image_embeddings)\n",
        "            \n",
        "            \n",
        "    image_embeddings = np.concatenate(embeddings)\n",
        "            \n",
        "    return image_embeddings"
      ],
      "metadata": {
        "id": "5W8Sn-ebcMYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_neighbors(df, embeddings, KNN = 50, isImage=False):\n",
        "    \n",
        "\n",
        "#     # cuml neighbors\n",
        "#     model = NearestNeighbors(n_neighbors = KNN)\n",
        "#     model.fit(embeddings)\n",
        "#     distances, indices = model.kneighbors(embeddings)\n",
        "#     print(distances.shape)\n",
        "#     predictions = []\n",
        "#     for k in tqdm(range(embeddings.shape[0])):\n",
        "#         if isImage:\n",
        "#             idx = np.where(distances[k,] < 3.1)[0]\n",
        "#         else:\n",
        "#             idx = np.where(distances[k,] < 0.70)[0]\n",
        "#         ids = indices[k,idx]\n",
        "#         posting_ids = df['posting_id'].iloc[ids].values\n",
        "#         predictions.append(posting_ids)\n",
        "        \n",
        "#     del model, distances, indices\n",
        "#     gc.collect()\n",
        "#     return df, predictions"
      ],
      "metadata": {
        "id": "R9YS2OYRcOe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get nearest neighbors distances and index information\n",
        "\n",
        "def get_knn_model(embeddings,KNN=50, metric='cosine'):\n",
        "    knnModel = NearestNeighbors(n_neighbors=KNN,metric=metric)\n",
        "    knnModel.fit(embeddings)\n",
        "#         distances, indices = knnModel.kneighbors(image_embeddings)\n",
        "    \n",
        "    return knnModel"
      ],
      "metadata": {
        "id": "bfrBVBi7cR-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def search_similar_images(queryFeatures, index, maxResults=5):\n",
        "#     results=[]\n",
        "    \n",
        "#     # loop over our index\n",
        "#     for i in range(0, len(index[\"features\"])):\n",
        "#         # compute the  distance euclidean between our query features\n",
        "#         # and the features for the current image in our index, then\n",
        "#         dist = euclidean(queryFeatures, index[\"features\"][i])\n",
        "#         results.append((dist, index['indexes'][i]))\n",
        "\n",
        "#     # sort the results and grab the top ones\n",
        "#     results = sorted(results)[:maxResults]\n",
        "\n",
        "#     # return the list of results\n",
        "#     return results"
      ],
      "metadata": {
        "id": "imlAIXmNcWsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
        "# get  Training image  path\n",
        "train_image_paths = get_images_path(train_df, CFG.TRAIN_DIR)"
      ],
      "metadata": {
        "id": "34r39h22cYT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  get Training Image embeddings and save it for later use\n",
        "test_transform =get_test_transforms()\n",
        "shopee_model = getPretrainedModel(loss_module='ArcFace',model_path=CFG.model_path_arcface, device=CFG.device)\n",
        "train_image_embeddings = getEmbeddings(train_image_paths, shopee_model, transform=test_transform)\n",
        "np.save(\"training_image_embeddings\", train_image_embeddings)"
      ],
      "metadata": {
        "id": "u6EOu3recats"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize"
      ],
      "metadata": {
        "id": "rW_eg7Mhce2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_canvas(train, random=False, COLS=4, ROWS=2, path=CFG.TRAIN_DIR+\"/\", isRecommending=False):\n",
        "    \n",
        "    for k in range(ROWS): \n",
        "        plt.figure(figsize=(20,5))\n",
        "        for j in range(COLS): \n",
        "            if random: row = np.random.randint(0,len(train))\n",
        "            else: row = COLS*k + j \n",
        "            name = train.iloc[row,1]\n",
        "            title = train.iloc[row,3]\n",
        "            posting_id = train.iloc[row,0]\n",
        "            label_g = train.iloc[row,4]\n",
        "            if isRecommending:\n",
        "                if j == 0 and row==0 :\n",
        "                    title_with_return = \"Query Image \\n\"\n",
        "                    title_with_return += \"-\"*20 + \"\\n Title :\"\n",
        "                else:\n",
        "                    title_with_return = \"Recommended Image {} \\n\".format(row)\n",
        "                    title_with_return += \"-\"*20 + \"\\n Title : \"\n",
        "                punctuation= '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "                for x in punctuation:\n",
        "                    title=title.replace(x,\"\")\n",
        "                title_with_return+= \" \"+ title[:min(len(title), 20)] \n",
        "            else:\n",
        "                title_with_return = \"\"\n",
        "            \n",
        "            img = cv2.imread(path+name)\n",
        "            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB )\n",
        "            plt.subplot(1,COLS,j+1)\n",
        "            plt.title(title_with_return)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img)\n",
        "        plt.show()\n",
        "        \n",
        "plot_canvas(train_df,random=True)"
      ],
      "metadata": {
        "id": "r8IL2_uZccqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Top k Recommendation"
      ],
      "metadata": {
        "id": "xNWix0_3cm9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_neighbors( train_embeddings, query_embeddings,KNN=50, metric_param='cosine'):\n",
        "    # we can get top neighbors based on different distance metric,in our case we are using \n",
        "    # cosine and euclidean metric\n",
        "    if metric_param == 'cosine':\n",
        "        # fit cosine distance medal on train image embddings\n",
        "        cosine_knnModel = get_knn_model(train_embeddings, KNN=KNN, metric='cosine')\n",
        "        # get top k neighbors distances and indices given metric for query embeddings\n",
        "        distances, indices = cosine_knnModel.kneighbors(query_embeddings)\n",
        "\n",
        "    else:\n",
        "        # fit euclidean distance modal on image embeddings\n",
        "        eucl_knnModel = get_knn_model(train_embeddings, KNN=KNN, metric='minkowski')\n",
        "        # get top k neighbors distances and indices given metric for query embeddings\n",
        "        distances, indices = eucl_knnModel.kneighbors(query_embeddings)\n",
        "    \n",
        "    return distances, indices"
      ],
      "metadata": {
        "id": "iFGT4xyAckkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_param = 'cosine'\n",
        "cosine_distances, cosine_indices = get_neighbors(\n",
        "                                    train_embeddings = train_image_embeddings,\n",
        "                                    query_embeddings = train_image_embeddings,\n",
        "                                    KNN=50,\n",
        "                                    metric_param='cosine'\n",
        "                                )\n",
        "\n",
        "np.save(\"cosine_distance_training_f1_0.9\", cosine_distances)\n",
        "\n",
        "np.save(\"top_50_similar_cosine_indices_training_f1_0.9\", cosine_indices)"
      ],
      "metadata": {
        "id": "oYrZVZhMctZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize based on cosine distance"
      ],
      "metadata": {
        "id": "cnWYkXdocxZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_sample_id =[505,506,3,9,33,94]"
      ],
      "metadata": {
        "id": "vm17lZhKcvbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in (testing_sample_id):\n",
        "\n",
        "    plt.figure(figsize=(20,3))\n",
        "    plt.plot(np.arange(50),cupy.asnumpy(cosine_distances[k,]),'o-')\n",
        "    plt.title('Image {} Distance From Train Row {} to Other Train Rows'.format(\"cosine\",k),size=16)\n",
        "    plt.ylabel('{} Distance to Train Row {}'.format(\"cosine\", k),size=14)\n",
        "    plt.xlabel('Index Sorted by {} Distance to Train Row {}'.format(\"cosine\",k),size=14)\n",
        "    plt.show()\n",
        "    \n",
        "    cluster = train_df.loc[cupy.asnumpy(cosine_indices[k,:5])] \n",
        "#     print(cluster)\n",
        "    plot_canvas(cluster, random=False, ROWS=1, COLS=5, isRecommending=True)"
      ],
      "metadata": {
        "id": "GCOpIeExc3UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize based on Euclidean Distance"
      ],
      "metadata": {
        "id": "vxkHnGmQc98X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "euc_distances, euc_indices = get_neighbors(\n",
        "                                    train_embeddings = train_image_embeddings,\n",
        "                                    query_embeddings = train_image_embeddings,\n",
        "                                    KNN=50,\n",
        "                                    metric_param='euclidean'\n",
        "                                )\n",
        "\n",
        "np.save(\"euclidean_distance_training_f1_0.9\", euc_distances)\n",
        "\n",
        "np.save(\"top_50_similar_euclidean_indices_training_f1_0.9\", euc_indices)"
      ],
      "metadata": {
        "id": "bL3RyMNsc5JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in (testing_sample_id):\n",
        "    plt.figure(figsize=(20,3))\n",
        "    plt.plot(np.arange(50),cupy.asnumpy(euc_distances[k,]),'o-')\n",
        "    plt.title('Image {} Distance From Train Row {} to Other Train Rows'.format(\"euclidean\",k),size=16)\n",
        "    plt.ylabel('{} Distance to Train Row {}'.format(\"euclidean\", k),size=14)\n",
        "    plt.xlabel('Index Sorted by Distance to Train Row {}'.format(k),size=14)\n",
        "    plt.show()\n",
        "    \n",
        "    cluster = train_df.loc[cupy.asnumpy(euc_indices[k,:5])] \n",
        "    plot_canvas(cluster, random=False, ROWS=1, COLS=5,isRecommending=True)"
      ],
      "metadata": {
        "id": "65g_LuiVdCCP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
